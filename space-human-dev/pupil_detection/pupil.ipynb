{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from src.mediapipe import GooMedia\n",
    "from src.utils import image_resize\n",
    "from src.visualize import draw_face_one_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_EAR(eye_points):\n",
    "    eye_points = np.array(eye_points)\n",
    "    A = np.linalg.norm(eye_points[1] - eye_points[5])\n",
    "    B = np.linalg.norm(eye_points[2] - eye_points[4])\n",
    "    C = np.linalg.norm(eye_points[0] - eye_points[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pupil(eye_gray, eye_color, iris_diameter):\n",
    "    avg_intensity = np.mean(eye_gray)\n",
    "    threshold_value = avg_intensity * 0.8\n",
    "    _, thresh = cv2.threshold(eye_gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.medianBlur(thresh, 5)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        M = cv2.moments(c)\n",
    "        if M['m00'] != 0:\n",
    "            cX, cY = int(M['m10'] / M['m00']), int(M['m01'] / M['m00'])\n",
    "            center = (cX, cY)\n",
    "            area = cv2.contourArea(c)\n",
    "            radius = int(np.sqrt(area / np.pi))\n",
    "            if 1 < radius < iris_diameter / 2:\n",
    "                normalized_pupil_size = (2 * radius) / iris_diameter\n",
    "                # Convert eye_color to uint8 if it's not already\n",
    "                eye_color_uint8 = eye_color.astype(np.uint8) if eye_color.dtype != np.uint8 else eye_color\n",
    "                # Draw circle on the uint8 image\n",
    "                cv2.circle(eye_color_uint8, center, radius, (0, 255, 0), 1)\n",
    "                return eye_color_uint8, normalized_pupil_size\n",
    "    return eye_color, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iris_size(landmarks, image_shape, iris_indices):\n",
    "    image_height, image_width = image_shape[:2]\n",
    "    iris_landmarks = [landmarks.landmark[i] for i in iris_indices]\n",
    "    iris_points = [(p.x * image_width, p.y * image_height) for p in iris_landmarks]\n",
    "    left_point = np.array(iris_points[0])\n",
    "    right_point = np.array(iris_points[2])\n",
    "    iris_diameter = np.linalg.norm(right_point - left_point)\n",
    "    return iris_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_region(image, face_landmarks, eye_indices):\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    # Get the coordinates of the eye landmarks\n",
    "    eye_landmarks = [face_landmarks.landmark[i] for i in eye_indices]\n",
    "    eye_points = np.array([\n",
    "        (int(p.x * image_width), int(p.y * image_height)) for p in eye_landmarks\n",
    "    ], dtype=np.int32)\n",
    "\n",
    "    # Calculate the bounding rectangle of the eye\n",
    "    x, y, w, h = cv2.boundingRect(eye_points)\n",
    "\n",
    "    # Crop the eye region from the original image\n",
    "    eye_region = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Adjust the eye landmarks to the cropped region\n",
    "    eye_points_cropped = eye_points - [x, y]\n",
    "    print(\"Original Eye Landmarks:\", eye_points)\n",
    "    print(\"Adjusted Eye Landmarks:\", eye_points_cropped)\n",
    "\n",
    "    return eye_region, eye_points_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figure(fig, filename):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    \n",
    "    # Convert to RGB if the image is in RGBA mode\n",
    "    if img.mode == 'RGBA':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    # Ensure the filename ends with .jpg\n",
    "    if not filename.lower().endswith('.jpg'):\n",
    "        filename = filename.rsplit('.', 1)[0] + '.jpg'\n",
    "    \n",
    "    img.save(filename, 'JPEG')\n",
    "    buf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, output_directory):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    frame = cv2.imread(image_path)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image_height, image_width, _ = frame.shape\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "        EAR_THRESHOLD = 0.25\n",
    "        results = face_mesh.process(frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                left_eye_indices = [33, 160, 158, 133, 153, 144]\n",
    "                left_eye_points = [(face_landmarks.landmark[i].x * image_width, face_landmarks.landmark[i].y * image_height) for i in left_eye_indices]\n",
    "                ear = calculate_EAR(left_eye_points)\n",
    "\n",
    "                if ear > EAR_THRESHOLD:\n",
    "                    left_iris_indices = [469, 470, 471, 472, 468]\n",
    "                    iris_diameter = calculate_iris_size(face_landmarks, frame.shape, left_iris_indices)\n",
    "                    left_eye_region, eye_points_cropped = get_eye_region(frame, face_landmarks, left_eye_indices)\n",
    "\n",
    "                    if left_eye_region.size != 0:\n",
    "                        eye_gray = cv2.cvtColor(left_eye_region, cv2.COLOR_RGB2GRAY)\n",
    "                        eye_color = left_eye_region.copy()\n",
    "                        pupil_frame, normalized_pupil_size = detect_pupil(eye_gray, eye_color, iris_diameter)\n",
    "\n",
    "                        # Convert pupil_frame to uint8 if it's not already\n",
    "                        pupil_frame_uint8 = pupil_frame.astype(np.uint8) if pupil_frame.dtype != np.uint8 else pupil_frame\n",
    "\n",
    "                        for point in eye_points_cropped:\n",
    "                            cv2.circle(pupil_frame_uint8, tuple(point), 1, (0, 0, 255), -1)\n",
    "\n",
    "                        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                        ax1.imshow(frame)\n",
    "                        ax1.set_title('Original Image')\n",
    "                        ax1.axis('off')\n",
    "                        ax2.imshow(left_eye_region)\n",
    "                        ax2.set_title('Left Eye Region')\n",
    "                        ax2.axis('off')\n",
    "                        ax3.imshow(pupil_frame_uint8)\n",
    "                        ax3.set_title('Detected Pupil')\n",
    "                        ax3.axis('off')\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        output_filename = os.path.join(output_directory, f\"pupil_detection_{os.path.basename(image_path).rsplit('.', 1)[0]}.jpg\")\n",
    "                        save_figure(fig, output_filename)\n",
    "                        plt.close(fig)\n",
    "\n",
    "                        if normalized_pupil_size:\n",
    "                            print(f\"Normalized Pupil Size: {normalized_pupil_size:.2f}\")\n",
    "                        else:\n",
    "                            print(\"Pupil size could not be determined.\")\n",
    "                        return\n",
    "                else:\n",
    "                    print(\"Left eye is closed, skipping pupil detection.\")\n",
    "                    return\n",
    "        print(\"No face detected in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(input_directory, output_directory):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(input_directory, filename)\n",
    "            print(f\"Processing image: {filename}\")\n",
    "            process_image(image_path, output_directory)\n",
    "            print(f\"Finished processing: {filename}\\n\")\n",
    "    print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: 36points_x25_y25.jpg\n",
      "Original Eye Landmarks: [[144 304]\n",
      " [155 299]\n",
      " [174 298]\n",
      " [195 308]\n",
      " [176 312]\n",
      " [157 312]]\n",
      "Adjusted Eye Landmarks: [[ 0  6]\n",
      " [11  1]\n",
      " [30  0]\n",
      " [51 10]\n",
      " [32 14]\n",
      " [13 14]]\n",
      "Normalized Pupil Size: 0.75\n",
      "Finished processing: 36points_x25_y25.jpg\n",
      "\n",
      "Processing image: 36points_x25_y42.jpg\n",
      "Original Eye Landmarks: [[165 315]\n",
      " [176 309]\n",
      " [195 308]\n",
      " [214 318]\n",
      " [196 322]\n",
      " [178 321]]\n",
      "Adjusted Eye Landmarks: [[ 0  7]\n",
      " [11  1]\n",
      " [30  0]\n",
      " [49 10]\n",
      " [31 14]\n",
      " [13 13]]\n",
      "Normalized Pupil Size: 0.76\n",
      "Finished processing: 36points_x25_y42.jpg\n",
      "\n",
      "Processing image: 36points_x25_y58.jpg\n",
      "Original Eye Landmarks: [[162 322]\n",
      " [174 318]\n",
      " [192 317]\n",
      " [212 326]\n",
      " [194 330]\n",
      " [175 330]]\n",
      "Adjusted Eye Landmarks: [[ 0  5]\n",
      " [12  1]\n",
      " [30  0]\n",
      " [50  9]\n",
      " [32 13]\n",
      " [13 13]]\n",
      "Normalized Pupil Size: 0.68\n",
      "Finished processing: 36points_x25_y58.jpg\n",
      "\n",
      "Processing image: 36points_x25_y75.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x25_y75.jpg\n",
      "\n",
      "Processing image: 36points_x25_y8.jpg\n",
      "Original Eye Landmarks: [[147 300]\n",
      " [158 294]\n",
      " [177 294]\n",
      " [197 305]\n",
      " [179 308]\n",
      " [160 308]]\n",
      "Adjusted Eye Landmarks: [[ 0  6]\n",
      " [11  0]\n",
      " [30  0]\n",
      " [50 11]\n",
      " [32 14]\n",
      " [13 14]]\n",
      "Normalized Pupil Size: 0.76\n",
      "Finished processing: 36points_x25_y8.jpg\n",
      "\n",
      "Processing image: 36points_x25_y92.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x25_y92.jpg\n",
      "\n",
      "Processing image: 36points_x42_y25.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x42_y25.jpg\n",
      "\n",
      "Processing image: 36points_x42_y42.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x42_y42.jpg\n",
      "\n",
      "Processing image: 36points_x42_y58.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x42_y58.jpg\n",
      "\n",
      "Processing image: 36points_x42_y75.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x42_y75.jpg\n",
      "\n",
      "Processing image: 36points_x42_y8.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x42_y8.jpg\n",
      "\n",
      "Processing image: 36points_x42_y92.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x42_y92.jpg\n",
      "\n",
      "Processing image: 36points_x58_y25.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x58_y25.jpg\n",
      "\n",
      "Processing image: 36points_x58_y42.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x58_y42.jpg\n",
      "\n",
      "Processing image: 36points_x58_y58.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x58_y58.jpg\n",
      "\n",
      "Processing image: 36points_x58_y75.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x58_y75.jpg\n",
      "\n",
      "Processing image: 36points_x58_y8.jpg\n",
      "Original Eye Landmarks: [[174 268]\n",
      " [185 262]\n",
      " [203 262]\n",
      " [222 273]\n",
      " [204 276]\n",
      " [187 276]]\n",
      "Adjusted Eye Landmarks: [[ 0  6]\n",
      " [11  0]\n",
      " [29  0]\n",
      " [48 11]\n",
      " [30 14]\n",
      " [13 14]]\n",
      "Normalized Pupil Size: 0.72\n",
      "Finished processing: 36points_x58_y8.jpg\n",
      "\n",
      "Processing image: 36points_x58_y92.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x58_y92.jpg\n",
      "\n",
      "Processing image: 36points_x75_y25.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x75_y25.jpg\n",
      "\n",
      "Processing image: 36points_x75_y42.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x75_y42.jpg\n",
      "\n",
      "Processing image: 36points_x75_y58.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x75_y58.jpg\n",
      "\n",
      "Processing image: 36points_x75_y75.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x75_y75.jpg\n",
      "\n",
      "Processing image: 36points_x75_y8.jpg\n",
      "Original Eye Landmarks: [[171 267]\n",
      " [182 262]\n",
      " [200 263]\n",
      " [219 273]\n",
      " [202 275]\n",
      " [184 275]]\n",
      "Adjusted Eye Landmarks: [[ 0  5]\n",
      " [11  0]\n",
      " [29  1]\n",
      " [48 11]\n",
      " [31 13]\n",
      " [13 13]]\n",
      "Normalized Pupil Size: 0.72\n",
      "Finished processing: 36points_x75_y8.jpg\n",
      "\n",
      "Processing image: 36points_x75_y92.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x75_y92.jpg\n",
      "\n",
      "Processing image: 36points_x8_y25.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x8_y25.jpg\n",
      "\n",
      "Processing image: 36points_x8_y42.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x8_y42.jpg\n",
      "\n",
      "Processing image: 36points_x8_y58.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x8_y58.jpg\n",
      "\n",
      "Processing image: 36points_x8_y75.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x8_y75.jpg\n",
      "\n",
      "Processing image: 36points_x8_y8.jpg\n",
      "Original Eye Landmarks: [[169 270]\n",
      " [181 264]\n",
      " [201 264]\n",
      " [221 274]\n",
      " [202 278]\n",
      " [182 278]]\n",
      "Adjusted Eye Landmarks: [[ 0  6]\n",
      " [12  0]\n",
      " [32  0]\n",
      " [52 10]\n",
      " [33 14]\n",
      " [13 14]]\n",
      "Normalized Pupil Size: 0.65\n",
      "Finished processing: 36points_x8_y8.jpg\n",
      "\n",
      "Processing image: 36points_x8_y92.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x8_y92.jpg\n",
      "\n",
      "Processing image: 36points_x92_y25.jpg\n",
      "Original Eye Landmarks: [[160 285]\n",
      " [171 281]\n",
      " [188 281]\n",
      " [206 290]\n",
      " [189 293]\n",
      " [172 293]]\n",
      "Adjusted Eye Landmarks: [[ 0  4]\n",
      " [11  0]\n",
      " [28  0]\n",
      " [46  9]\n",
      " [29 12]\n",
      " [12 12]]\n",
      "Normalized Pupil Size: 0.76\n",
      "Finished processing: 36points_x92_y25.jpg\n",
      "\n",
      "Processing image: 36points_x92_y42.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x92_y42.jpg\n",
      "\n",
      "Processing image: 36points_x92_y58.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x92_y58.jpg\n",
      "\n",
      "Processing image: 36points_x92_y75.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x92_y75.jpg\n",
      "\n",
      "Processing image: 36points_x92_y8.jpg\n",
      "Original Eye Landmarks: [[157 270]\n",
      " [168 263]\n",
      " [186 264]\n",
      " [204 276]\n",
      " [187 279]\n",
      " [170 279]]\n",
      "Adjusted Eye Landmarks: [[ 0  7]\n",
      " [11  0]\n",
      " [29  1]\n",
      " [47 13]\n",
      " [30 16]\n",
      " [13 16]]\n",
      "Normalized Pupil Size: 0.82\n",
      "Finished processing: 36points_x92_y8.jpg\n",
      "\n",
      "Processing image: 36points_x92_y92.jpg\n",
      "Left eye is closed, skipping pupil detection.\n",
      "Finished processing: 36points_x92_y92.jpg\n",
      "\n",
      "All images processed.\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = r'images\\inputs\\artur\\36points'\n",
    "    output_directory = r'images\\outputs\\pupil_images'\n",
    "    process_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: 36points_x25_y25.jpg\n",
      "Processing image: 36points_x25_y42.jpg\n",
      "Processing image: 36points_x25_y58.jpg\n",
      "Processing image: 36points_x25_y75.jpg\n",
      "Processing image: 36points_x25_y8.jpg\n",
      "Processing image: 36points_x25_y92.jpg\n",
      "Processing image: 36points_x42_y25.jpg\n",
      "Processing image: 36points_x42_y42.jpg\n",
      "Processing image: 36points_x42_y58.jpg\n",
      "Processing image: 36points_x42_y75.jpg\n",
      "Processing image: 36points_x42_y8.jpg\n",
      "Processing image: 36points_x42_y92.jpg\n",
      "Processing image: 36points_x58_y25.jpg\n",
      "Processing image: 36points_x58_y42.jpg\n",
      "Processing image: 36points_x58_y58.jpg\n",
      "Processing image: 36points_x58_y75.jpg\n",
      "Processing image: 36points_x58_y8.jpg\n",
      "Processing image: 36points_x58_y92.jpg\n",
      "Processing image: 36points_x75_y25.jpg\n",
      "Processing image: 36points_x75_y42.jpg\n",
      "Processing image: 36points_x75_y58.jpg\n",
      "Processing image: 36points_x75_y75.jpg\n",
      "Processing image: 36points_x75_y8.jpg\n",
      "Processing image: 36points_x75_y92.jpg\n",
      "Processing image: 36points_x8_y25.jpg\n",
      "Processing image: 36points_x8_y42.jpg\n",
      "Processing image: 36points_x8_y58.jpg\n",
      "Processing image: 36points_x8_y75.jpg\n",
      "Processing image: 36points_x8_y8.jpg\n",
      "Processing image: 36points_x8_y92.jpg\n",
      "Processing image: 36points_x92_y25.jpg\n",
      "Processing image: 36points_x92_y42.jpg\n",
      "Processing image: 36points_x92_y58.jpg\n",
      "Processing image: 36points_x92_y75.jpg\n",
      "Processing image: 36points_x92_y8.jpg\n",
      "Processing image: 36points_x92_y92.jpg\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for filename in os.listdir(input_directory):\n",
    "\n",
    "    image_path = os.path.join(input_directory, filename)\n",
    "    print(f\"Processing image: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space_human",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
